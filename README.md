# Работа 3.3.4.<br>Решение задачи быстрого поиска количества вхождений слова в большой текст на английском языке при помощи алгоритма хэш-таблицы и оптимизации времени поиска
## Содержание
- [0. АННОТАЦИЯ](#аннотация)
- [1. ВВЕДЕНИЕ](#введение)
- [2. МЕТОДИКА](#методика)
- [3. РЕЗУЛЬТАТЫ И ИХ ОБСУЖДЕНИЕ](#результаты-и-их-обсуждение)
- [4. ВЫВОДЫ](#выводы)
- [5. ПРИЛОЖЕНИЯ](#приложения)

## Аннотация
Для решения задачи быстрого поиска количества вхождений слова в большой текст на английском языке я выбрал алгоритм хэш-таблицы. В первой версии хэш таблицы поиск слова занял 21.5 с . С ключом оптимизации -O3 время поиска составило 20.6 с. Затем я провёл анализ профиля программы, полученного с помощью профилировщика perf, для определения узких мест производительности. 


## Введение
В таких областях, как ..., часто появляется необхоимость решения задачи быстрого поиска количества вхождений слова в большой текст.

Первым способом решения этой задачи является линейный перебор всех слов в тексте. Он имеет простую реализацию и подходит для достаточно маленьких текстов, таких как одиночный поисковой запрос в браузере. Однако поиск количества вхождений слова в текст большего размера таким методом будет занимать огромное время, так как будет происходить сравнение слова со всеми словами в тексте. Линейный перебор можно оптимизировать, например, с использованием интринсиков и при помощи развёртки цикла, однако время сравнения слова с каждым из, например, 100000 слов, всё равно займёт колоссальное время, которое будет увеличиваться при увеличении размера текста. Исходя из этого можно сделать вывод, что метод линейного перебора всех слов в тексте, хоть и является простым для реализации, не подходит для быстрого поиска количества вхождений слова в текст.

Более оптимальным решением является использование алгоритма хэш-таблицы. Этот метод подразумевает разделение всех слов в тесте на корзины в зависимости от значения их хэша. Для поиска слова в хэш-таблице необходимо рассчитать хэш этого слова и провести линейный поиск уже для меньшего количества слов с таким же хэшом. Для хэш-таблиц применяется такая характеристика, как load-фактор, которая показывает сколько в среднем слов приходится на одну корзину. В хороших хэш-таблицах load-фактор находится в диапазоне от 1.5 до 2. Это говорит о том, что линейный поиск по корзине может занимать в тысячи раз меньше времени, чем по всему тексту в целом, поэтому поиск количества вхождений слова в большой текст при помощи хэш-таблицы происходит гораздо быстрее, чем линейный перебор большого текста. К тому же время поиска с использованием алгоритма хэш-таблицы не зависит от размера текста, так как количество слов в корзине регулируется при помощи увеличения или уменьшения количества корзин, а время рассчёта хэша слова, очевидно, не зависит от размера текста.

## Методика
В качестве id-номера может использоваться, например, 

## Результаты и их обсуждение

В первой версии хэш таблицы поиск 500 000 слов в хэш-таблице, состоящей из ≈ 20 000 уникальных слов, выполнялся в среднем за (19.88 ± 0.25) с. С ключом оптимизации -O3 время поиска составило (18.89 ± 0.22) с. 

По профилю программы, полученному при помощи инструментов Perf и Valgrind, я определил, что наибольшее время уходит на сравнение слов функцией strcmp. Я заметил, что практически все английские слова имеют длину меньше 32 букв, поэтому решил переписать функцию strcmp, используя интринсики, поместив слово в 256-битный целочисленный вектор с типом данных С++ __m256i. Таким образом, во второй версии программы с моей inline функцией MyStrcmp с интринсиками вместо стандартной функции strcmp на поиск 500 000 слов в хэш-таблице, состоящей из ≈ 20 000 уникальных слов, тратилось в среднем (13.25 ± 0.15) с. В результате этой оптимизации я добился ускорения работы программы на 42.6 %.

<div align="center"><img src="img/First/PerfOutputFirstVersionWithoutOptimizationKeys.png"></div><br>
  <div align="center"> Рис. 3. Фрагмент профиля, полученного инстументом perf, первой версии программы для быстрого поиска количества вхождений слова в текст без ключей оптимизации.</div><br>

<div align="center"><img src="img/First/PerfOutputFirstVersionWithO3.png"></div><br>
  <div align="center"> Рис. 4. Фрагмент профиля, полученного инстументом perf, первой версии программы для быстрого поиска количества вхождений слова в текст с ключом оптимизации -O3.</div><br>

### Модель

### Результаты измерений

## Выводы

## Приложения
### Ход работы

Написав первую работающую версию хэш-таблицы я столкнулся с проблемой. Она заключалась в том, что по профилю, полученному с помощью perf и valgrind, на выполнение функции strlen уходило 96% времени. Я подумал, что дело в стандартной реализации strlen, поэтому написал свою реализацию strlen на ассемблере, которая сравнивала слова длины <= 32 символа. Однако после этого я увидел, что скорость почти не увеличилась, и на выполнение strlen всё равно уходила большая часть времени. Оказалось, что функция strlen вызывалась не только в моих функциях. В большинстве случаев она вызывалась из стандартной функции sscanf (const char *str, const char *format, ...). Тогда я исправил свою реализацию хэш-таблицы так, чтобы она не содержала вызовов sscanf, на которые уходила большая часть времени, заменив их на ручную обработку входящего текста, и получил первую версию своей реализации хэш таблицы для быстрого поиска количества вхождений слова в большой текст.
Вторая версия, как писал, среднее время 13.251 ±0.146.

### Результаты измерений 

| №  | Время, с    |
|----|-------------|
| 1  | 18.582256   |
| 2  | 19.021634   |
| 3  | 19.239251   |
| 4  | 19.505591   |
| 5  | 19.576650   |
| 6  | 19.669379   |
| 7  | 19.666065   |
| 8  | 19.840076   |
| 9  | 19.999106   |
| 10 | 19.971924   |
| 11 | 20.183662   |
| 12 | 20.322716   |
| 13 | 20.145599   |
| 14 | 20.230449   |
| 15 | 20.219437   |
| 16 | 20.134458   |
| 17 | 20.209993   |
| 18 | 20.197357   |
| 19 | 20.011992   |
| 20 | 20.324118   |
<div align="center"> Таблица 1. Время, потраченное на поиск 500 000 слов в хэш таблице, составленной по словам из 4 томов Войны и мира Л.Н. Толстого (≈ 20 000 уникальных слов), в первой версии без ключей оптимизации. Проведено 20 измерений.</div><br>

| №  | Время, с    |
|----|-------------|
| 1  | 17.708388   |
| 2  | 17.914491   |
| 3  | 18.229700   |
| 4  | 18.525427   |
| 5  | 18.601768   |
| 6  | 19.586490   |
| 7  | 19.221907   |
| 8  | 18.935873   |
| 9  | 18.935682   |
| 10 | 18.814731   |
| 11 | 19.094307   |
| 12 | 18.918449   |
| 13 | 19.017228   |
| 14 | 19.003576   |
| 15 | 19.247027   |
| 16 | 19.119530   |
| 17 | 19.140599   |
| 18 | 19.260793   |
| 19 | 19.193091   |
| 20 | 19.360809   |
<div align="center"> Таблица 2. Время, потраченное на поиск 500 000 слов в хэш таблице, составленной по словам из 4 томов Войны и мира Л.Н. Толстого (≈ 20 000 уникальных слов), в первой версии с ключом оптимизации -О3. Проведено 20 измерений.</div><br>

| №  | Время, с    |
|----|-------------|
| 1  | 12.392496   |
| 2  | 12.349935   |
| 3  | 12.663802   |
| 4  | 12.927390   |
| 5  | 13.147637   |
| 6  | 13.085441   |
| 7  | 13.067749   |
| 8  | 13.121255   |
| 9  | 13.233181   |
| 10 | 13.219976   |
| 11 | 13.140689   |
| 12 | 13.248764   |
| 13 | 13.286591   |
| 14 | 13.289942   |
| 15 | 13.369410   |
| 16 | 13.390029   |
| 17 | 13.388041   |
| 18 | 13.335193   |
| 19 | 13.339926   |
| 20 | 13.316800   |
<div align="center"> Таблица 3. Время, потраченное на поиск 500 000 слов в хэш таблице, составленной по словам из 4 томов Войны и мира Л.Н. Толстого (≈ 20 000 уникальных слов) с ключом оптимизации -О3 с использованием моей inline функции strcmp с интринсиками. Проведено 20 измерений.</div><br>
