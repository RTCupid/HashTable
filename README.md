# Работа 3.3.4.<br>Решение задачи быстрого поиска количества вхождений слова в большой текст на английском языке при помощи алгоритма хэш-таблицы и оптимизации времени поиска
## Содержание
- [0. АННОТАЦИЯ](#аннотация)
- [1. ВВЕДЕНИЕ](#введение)
- [2. МЕТОДИКА](#методика)
- [3. РЕЗУЛЬТАТЫ И ИХ ОБСУЖДЕНИЕ](#результаты-и-их-обсуждение)
- [4. ВЫВОДЫ](#выводы)
- [5. ПРИЛОЖЕНИЯ](#приложения)

## Аннотация
Для решения задачи быстрого поиска количества вхождений слова в большой текст на английском языке я выбрал алгоритм хэш-таблицы. В первой версии хэш таблицы поиск слова занял 21.5 с . С ключом оптимизации -O3 время поиска составило 20.6 с. Затем я провёл анализ профиля программы, полученного с помощью профилировщика perf, для определения узких мест производительности. 


## Введение
В таких областях, как ..., часто появляется необхоимость решения задачи быстрого поиска количества вхождений слова в большой текст.

Первым способом решения этой задачи является линейный перебор всех слов в тексте. Он имеет простую реализацию и подходит для достаточно маленьких текстов, таких как одиночный поисковой запрос в браузере. Однако поиск количества вхождений слова в текст большего размера таким методом будет занимать огромное время, так как будет происходить сравнение слова со всеми словами в тексте. Линейный перебор можно оптимизировать, например, с использованием интринсиков и при помощи развёртки цикла, однако время сравнения слова с каждым из, например, 100000 слов, всё равно займёт колоссальное время, которое будет увеличиваться при увеличении размера текста. Исходя из этого можно сделать вывод, что метод линейного перебора всех слов в тексте, хоть и является простым для реализации, не подходит для быстрого поиска количества вхождений слова в текст.

Более оптимальным решением является использование алгоритма хэш-таблицы. Этот метод подразумевает разделение всех слов в тесте на корзины в зависимости от значения их хэша. Для поиска слова в хэш-таблице необходимо рассчитать хэш этого слова и провести линейный поиск уже для меньшего количества слов с таким же хэшом. Для хэш-таблиц применяется такая характеристика, как load-фактор, которая показывает сколько в среднем слов приходится на одну корзину. В хороших хэш-таблицах load-фактор находится в диапазоне от 1.5 до 2. Это говорит о том, что линейный поиск по корзине может занимать в тысячи раз меньше времени, чем по всему тексту в целом, поэтому поиск количества вхождений слова в большой текст при помощи хэш-таблицы происходит гораздо быстрее, чем линейный перебор большого текста. К тому же время поиска с использованием алгоритма хэш-таблицы не зависит от размера текста, так как количество слов в корзине регулируется при помощи увеличения или уменьшения количества корзин, а время рассчёта хэша слова, очевидно, не зависит от размера текста.

## Методика
В качестве id-номера может использоваться, например, 

## Результаты и их обсуждение

В первой версии хэш таблицы поиск слова занял 21.5 с . С ключом оптимизации -O3 время поиска составило 20.6 с. По профилю программы, . 

<div align="center"><img src="img/First/PerfOutputFirstVersionWithoutOptimizationKeys.png"></div><br>
  <div align="center"> Рис. 3. Фрагмент профиля, полученного инстументом perf, первой версии программы для быстрого поиска количества вхождений слова в текст без ключей оптимизации.</div><br>

<div align="center"><img src="img/First/PerfOutputFirstVersionWithO3.png"></div><br>
  <div align="center"> Рис. 4. Фрагмент профиля, полученного инстументом perf, первой версии программы для быстрого поиска количества вхождений слова в текст с ключом оптимизации -O3.</div><br>

### Модель

### Результаты измерений

## Выводы

## Приложения
### Ход работы

Написав первую работающую версию хэш-таблицы я столкнулся с проблемой. Она заключалась в том, что по профилю, полученному с помощью perf и valgrind, на выполнение функции strlen уходило 96% времени. Я подумал, что дело в стандартной реализации strlen, поэтому написал свою реализацию strlen на ассемблере, которая сравнивала слова длины <= 32 символа. Однако после этого я увидел, что скорость почти не увеличилась, и на выполнение strlen всё равно уходила большая часть времени. Оказалось, что функция strlen вызывалась не только в моих функциях. В большинстве случаев она вызывалась из стандартной функции sscanf (const char *str, const char *format, ...). Тогда я исправил свою реализацию хэш-таблицы так, чтобы она не содержала вызовов sscanf, на которые уходила большая часть времени, заменив их на ручную обработку входящего текста, и получил первую версию своей реализации хэш таблицы для быстрого поиска количества вхождений слова в большой текст.

<div align="center"><img src="img/First/FirstVersionWithoutOptimizationKeys.png"></div><br>
  <div align="center"> Рис. 1. First version without optimization keys</div><br>

<div align="center"><img src="img/First/FirstVersionWithO3.png"></div><br>
  <div align="center"> Рис. 2. First version with -O3</div><br>


